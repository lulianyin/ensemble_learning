{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bagging思想的实质是：通过Bootstrap 的方式对全样本数据集进行抽样得到抽样子集，对不同的子集使用同一种基本模型进行拟合，然后投票得出最终的预测。-> Bagging主要通过降低方差的方式减少预测误差。\n",
    "* Boosting提升，使用同一组数据集进行反复学习，得到一系列简单模型，然后组合这些模型构成一个预测性能十分强大的机器学习模型。-> 不断减少偏差的形式，\n",
    "\n",
    "这里介绍两类常用的Boosting方式：Adaptive Boosting 和 Gradient Boosting 以及它们的变体Xgboost、LightGBM以及Catboost。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting方法的基本思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在正式介绍Boosting思想之前，我想先介绍两个例子：                   \n",
    "第一个例子：不知道大家有没有做过错题本，我们将每次测验的错的题目记录在错题本上，不停的翻阅，直到我们完全掌握(也就是能够在考试中能够举一反三)。              \n",
    "第二个例子：对于一个复杂任务来说，将多个专家的判断进行适当的综合所作出的判断，要比其中任何一个专家单独判断要好。实际上这是一种“三个臭皮匠顶个诸葛亮的道理”。                 \n",
    "这两个例子都说明Boosting的道理，也就是不错地重复学习达到最终的要求。  \n",
    "\n",
    "> 备注，感觉第二个例子更像是bagging，或者投票。如果专家分别负责不同的部分，是不同领域的专家，应该更合理。\n",
    "\n",
    "Boosting的提出与发展离不开Valiant和 Kearns的努力，历史上正是Valiant和 Kearns提出了\"强可学习\"和\"弱可学习\"的概念。那什么是\"强可学习\"和\"弱可学习\"呢？在概率近似正确PAC学习的框架下：            \n",
    "  - 弱学习：识别错误率小于1/2（即准确率仅比随机猜测略高的学习算法）                     \n",
    "  - 强学习：识别准确率很高并能在多项式时间内完成的学习算法                                   \n",
    "\n",
    "非常有趣的是，在PAC 学习的框架下，强可学习和弱可学习是等价的，也就是说一个概念是强可学习的充分必要条件是这个概念是弱可学习的。这样一来，问题便是：在学习中，如果已经发现了弱可学习算法，能否将他提升至强可学习算法。因为，弱可学习算法比强可学习算法容易得多。提升方法就是从弱学习算法出发，反复学习，得到一系列弱分类器(又称为基本分类器)，然后通过一定的形式去组合这些弱分类器构成一个强分类器。大多数的Boosting方法都是通过改变训练数据集的概率分布(训练数据不同样本的权值)，针对不同概率分布的数据调用弱分类算法学习一系列的弱分类器。              \n",
    "对于Boosting方法来说，有两个问题需要给出答案：第一个是每一轮学习应该如何改变数据的概率分布，第二个是如何将各个弱分类器组合起来。关于这两个问题，不同的Boosting算法会有不同的答案，我们接下来介绍一种最经典的Boosting算法----Adaboost，我们需要理解Adaboost是怎么处理这两个问题以及为什么这么处理的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adaboost算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost的基本原理**                             \n",
    "\n",
    "对于Adaboost来说，解决上述的两个问题的方式是：\n",
    "1. 提高那些被前一轮分类器错误分类的样本的权重，而降低那些被正确分类的样本的权重。这样一来，那些在上一轮分类器中没有得到正确分类的样本，由于其权重的增大而在后一轮的训练中“备受关注”。\n",
    "2. 各个弱分类器的组合是通过采取加权多数表决的方式，具体来说，加大分类错误率低的弱分类器的权重，因为这些分类器能更好地完成分类任务，而减小分类错误率较大的弱分类器的权重，使其在表决中起较小的作用。                          \n",
    "现在，我们来具体介绍Adaboost算法：(参考李航老师的《统计学习方法》)                       \n",
    "假设给定一个二分类的训练数据集：$T=\\left\\{\\left(x_{1}, y_{1}\\right),\\left(x_{2}, y_{2}\\right), \\cdots,\\left(x_{N}, y_{N}\\right)\\right\\}$，其中每个样本点由特征与类别组成。特征$x_{i} \\in \\mathcal{X} \\subseteq \\mathbf{R}^{n}$，类别$y_{i} \\in \\mathcal{Y}=\\{-1,+1\\}$，$\\mathcal{X}$是特征空间，$ \\mathcal{Y}$是类别集合，输出最终分类器$G(x)$。Adaboost算法如下：                 \n",
    "(1) 初始化训练数据的分布：$D_{1}=\\left(w_{11}, \\cdots, w_{1 i}, \\cdots, w_{1 N}\\right), \\quad w_{1 i}=\\frac{1}{N}, \\quad i=1,2, \\cdots, N$                       \n",
    "(2) 对于m=1,2,...,M            \n",
    "   - 使用具有权值分布$D_m$的训练数据集进行学习，得到基本分类器：$G_{m}(x): \\mathcal{X} \\rightarrow\\{-1,+1\\}$                  \n",
    "   - 计算$G_m(x)$在训练集上的分类误差率$e_{m}=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)$                   \n",
    "   - 计算$G_m(x)$的系数$\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}$，这里的log是自然对数ln                         \n",
    "   - 更新训练数据集的权重分布                \n",
    "   $$\n",
    "   \\begin{array}{c}\n",
    "   D_{m+1}=\\left(w_{m+1,1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N}\\right) \\\\\n",
    "   w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, N\n",
    "   \\end{array}\n",
    "   $$                       \n",
    "   这里的$Z_m$是规范化因子，使得$D_{m+1}$称为概率分布，$Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)$                          \n",
    "\n",
    "(3) 构建基本分类器的线性组合$f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)$，得到最终的分类器                       \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G(x) &=\\operatorname{sign}(f(x)) \\\\\n",
    "&=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)\\right)\n",
    "\\end{aligned}\n",
    "$$                          \n",
    "\n",
    "下面对Adaboost算法做如下说明：                                            \n",
    "对于步骤(1)，假设训练数据的权值分布是均匀分布，是为了使得第一次没有先验信息的条件下每个样本在基本分类器的学习中作用一样。                         \n",
    "对于步骤(2)，每一次迭代产生的基本分类器$G_m(x)$在加权训练数据集上的分类错误率$\\begin{aligned}e_{m} &=\\sum_{i=1}^{N} P\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right) =\\sum_{G_{m}\\left(x_{i}\\right) \\neq y_{i}} w_{m i}\\end{aligned}$代表了在$G_m(x)$中分类错误的样本权重和，这点直接说明了权重分布$D_m$与$G_m(x)$的分类错误率$e_m$有直接关系。同时，在步骤(2)中，计算基本分类器$G_m(x)$的系数$\\alpha_m$，$\\alpha_{m}=\\frac{1}{2} \\log \\frac{1-e_{m}}{e_{m}}$，它表示了$G_m(x)$在最终分类器的重要性程度，$\\alpha_m$的取值由基本分类器$G_m(x)$的分类错误率有直接关系，当$e_{m} \\leqslant \\frac{1}{2}$时，$\\alpha_{m} \\geqslant 0$，并且$\\alpha_m$随着$e_m$的减少而增大，因此分类错误率越小的基本分类器在最终分类器的作用越大！                       \n",
    "**最重要的，对于步骤(2)中的样本权重的更新：  **                                    \n",
    "$$\n",
    "w_{m+1, i}=\\left\\{\\begin{array}{ll}\n",
    "\\frac{w_{m i}}{Z_{m}} \\mathrm{e}^{-\\alpha_{m}}, & G_{m}\\left(x_{i}\\right)=y_{i} \\\\\n",
    "\\frac{w_{m i}}{Z_{m}} \\mathrm{e}^{\\alpha_{m}}, & G_{m}\\left(x_{i}\\right) \\neq y_{i}\n",
    "\\end{array}\\right.\n",
    "$$                        \n",
    "因此，从上式可以看到：被基本分类器$G_m(x)$错误分类的样本的权重扩大，被正确分类的样本权重减少，二者相比相差$\\mathrm{e}^{2 \\alpha_{m}}=\\frac{1-e_{m}}{e_{m}}$倍。                             \n",
    "对于步骤(3)，线性组合$f(x)$实现了将M个基本分类器的加权表决，系数$\\alpha_m$标志了基本分类器$G_m(x)$的重要性，值得注意的是：所有的$\\alpha_m$之和不为1。$f(x)$的符号决定了样本x属于哪一类。             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们使用一组简单的数据来手动计算Adaboost算法的过程：(例子来源：http://www.csie.edu.tw)                                                               \n",
    "\n",
    "训练数据如下表，假设基本分类器的形式是一个分割$x<v$或$x>v$表示，阈值v由该基本分类器在训练数据集上分类错误率$e_m$最低确定。                                                \n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "\\hline \\text { 序号 } & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\\\\n",
    "\\hline x & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\\\\n",
    "y & 1 & 1 & 1 & -1 & -1 & -1 & 1 & 1 & 1 & -1 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$                                          \n",
    "解：                        \n",
    "初始化样本权值分布\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{1} &=\\left(w_{11}, w_{12}, \\cdots, w_{110}\\right) \\\\\n",
    "w_{1 i} &=0.1, \\quad i=1,2, \\cdots, 10\n",
    "\\end{aligned}\n",
    "$$                                  \n",
    "对m=1:                      \n",
    "   - 在权值分布$D_1$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=2.5时分类误差率最低，那么基本分类器为：\n",
    "   $$\n",
    "   G_{1}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x<2.5 \\\\\n",
    "   -1, & x>2.5\n",
    "   \\end{array}\\right.\n",
    "   $$                         \n",
    "   - $G_1(x)$在训练数据集上的误差率为$e_{1}=P\\left(G_{1}\\left(x_{i}\\right) \\neq y_{i}\\right)=0.3$。                                           \n",
    "   - 计算$G_1(x)$的系数：$\\alpha_{1}=\\frac{1}{2} \\log \\frac{1-e_{1}}{e_{1}}=0.4236$               \n",
    "   - 更新训练数据的权值分布：                  \n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   D_{2}=&\\left(w_{21}, \\cdots, w_{2 i}, \\cdots, w_{210}\\right) \\\\\n",
    "   w_{2 i}=& \\frac{w_{1 i}}{Z_{1}} \\exp \\left(-\\alpha_{1} y_{i} G_{1}\\left(x_{i}\\right)\\right), \\quad i=1,2, \\cdots, 10 \\\\\n",
    "   D_{2}=&(0.07143,0.07143,0.07143,0.07143,0.07143,0.07143,\\\\\n",
    "   &0.16667,0.16667,0.16667,0.07143) \\\\\n",
    "   f_{1}(x) &=0.4236 G_{1}(x)\n",
    "   \\end{aligned}\n",
    "   $$\n",
    "\n",
    "对于m=2：                   \n",
    "   - 在权值分布$D_2$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=8.5时分类误差率最低，那么基本分类器为：                  \n",
    "   $$\n",
    "   G_{2}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x<8.5 \\\\\n",
    "   -1, & x>8.5\n",
    "   \\end{array}\\right.\n",
    "   $$                       \n",
    "   - $G_2(x)$在训练数据集上的误差率为$e_2 = 0.2143$                    \n",
    "   - 计算$G_2(x)$的系数：$\\alpha_2 = 0.6496$                        \n",
    "   - 更新训练数据的权值分布：                  \n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   D_{3}=&(0.0455,0.0455,0.0455,0.1667,0.1667,0.1667\\\\\n",
    "   &0.1060,0.1060,0.1060,0.0455) \\\\\n",
    "   f_{2}(x) &=0.4236 G_{1}(x)+0.6496 G_{2}(x)\n",
    "   \\end{aligned}\n",
    "   $$                   \n",
    "   \n",
    "对m=3：                          \n",
    "   - 在权值分布$D_3$的训练数据集上，遍历每个结点并计算分类误差率$e_m$，阈值取v=5.5时分类误差率最低，那么基本分类器为：                     \n",
    "   $$\n",
    "   G_{3}(x)=\\left\\{\\begin{array}{ll}\n",
    "   1, & x>5.5 \\\\\n",
    "   -1, & x<5.5\n",
    "   \\end{array}\\right.\n",
    "   $$                               \n",
    "   - $G_3(x)$在训练数据集上的误差率为$e_3 = 0.1820$                       \n",
    "   - 计算$G_3(x)$的系数：$\\alpha_3 = 0.7514$                                 \n",
    "   - 更新训练数据的权值分布：                    \n",
    "   $$\n",
    "   D_{4}=(0.125,0.125,0.125,0.102,0.102,0.102,0.065,0.065,0.065,0.125)\n",
    "   $$                       \n",
    "   \n",
    "于是得到：$f_{3}(x)=0.4236 G_{1}(x)+0.6496 G_{2}(x)+0.7514 G_{3}(x)$，分类器$\\operatorname{sign}\\left[f_{3}(x)\\right]$在训练数据集上的误分类点的个数为0。                                \n",
    "于是得到最终分类器为：$G(x)=\\operatorname{sign}\\left[f_{3}(x)\\right]=\\operatorname{sign}\\left[0.4236 G_{1}(x)+0.6496 G_{2}(x)+0.7514 G_{3}(x)\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**下面，我们使用sklearn对Adaboost算法进行建模：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次案例我们使用一份UCI的机器学习库里的开源数据集：葡萄酒数据集，该数据集可以在 ( https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data )上获得。该数据集包含了178个样本和13个特征，从不同的角度对不同的化学特性进行描述，我们的任务是根据这些数据预测红酒属于哪一个类别。(案例来源《python机器学习(第二版》)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入数据科学相关工具包：\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据：         \n",
    "wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None)\n",
    "wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols','Flavanoids', 'Nonflavanoid phenols', \n",
    "                'Proanthocyanins','Color intensity', 'Hue','OD280/OD315 of diluted wines','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels [1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据查看：\n",
    "print(\"Class labels\",np.unique(wine[\"Class label\"]))\n",
    "wine.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对数据做简单解读：                    \n",
    "   - Class label：分类标签         \n",
    "   - Alcohol：酒精                   \n",
    "   - Malic acid：苹果酸                      \n",
    "   - Ash：灰                  \n",
    "   - Alcalinity of ash：灰的碱度                  \n",
    "   - Magnesium：镁                     \n",
    "   - Total phenols：总酚                      \n",
    "   - Flavanoids：黄酮类化合物                      \n",
    "   - Nonflavanoid phenols：非黄烷类酚类                      \n",
    "   - Proanthocyanins：原花青素                     \n",
    "   - Color intensity：色彩强度                 \n",
    "   - Hue：色调                       \n",
    "   - OD280/OD315 of diluted wines：稀释酒OD280 OD350                      \n",
    "   - Proline：脯氨酸                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 仅仅考虑2，3类葡萄酒，去除1类\n",
    "wine = wine[wine['Class label'] != 1]\n",
    "y = wine['Class label'].values\n",
    "X = wine[['Alcohol','OD280/OD315 of diluted wines']].values\n",
    "\n",
    "# 将分类标签变成二进制编码：\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 按8：2分割训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1,stratify=y)  # stratify参数代表了按照y的类别等比例抽样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 0.916/0.875\n"
     ]
    }
   ],
   "source": [
    "# 使用单一决策树建模\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "tree = tree.fit(X_train,y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train,y_train_pred)\n",
    "tree_test = accuracy_score(y_test,y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' % (tree_train,tree_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train/test accuracies 0.937/0.917\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn实现Adaboost(基分类器为决策树)\n",
    "'''\n",
    "AdaBoostClassifier相关参数：\n",
    "base_estimator：基本分类器，默认为DecisionTreeClassifier(max_depth=1)\n",
    "n_estimators：终止迭代的次数\n",
    "learning_rate：学习率\n",
    "algorithm：训练的相关算法，{'SAMME'，'SAMME.R'}，默认='SAMME.R'\n",
    "random_state：随机种子\n",
    "'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(base_estimator=tree,n_estimators=20,learning_rate=0.1,random_state=1)\n",
    "ada = ada.fit(X_train,y_train)\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train,y_train_pred)\n",
    "ada_test = accuracy_score(y_test,y_test_pred)\n",
    "print('Adaboost train/test accuracies %.3f/%.3f' % (ada_train,ada_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果分析：单层决策树似乎对训练数据欠拟合，而Adaboost模型正确地预测了训练数据的所有分类标签，而且与单层决策树相比，Adaboost的测试性能也略有提高。然而，为什么模型在训练集和测试集的性能相差这么大呢？我们使用图像来简单说明下这个道理！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出单层决策树与Adaboost的决策边界：\n",
    "x_min = X_train[:, 0].min() - 1\n",
    "x_max = X_train[:, 0].max() + 1\n",
    "y_min = X_train[:, 1].min() - 1\n",
    "y_max = X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n",
    "f, axarr = plt.subplots(nrows=1, ncols=2,sharex='col',sharey='row',figsize=(12, 6))\n",
    "for idx, clf, tt in zip([0, 1],[tree, ada],['Decision tree', 'Adaboost']):\n",
    "    clf.fit(X_train, y_train)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    axarr[idx].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx].scatter(X_train[y_train==0, 0],X_train[y_train==0, 1],c='blue', marker='^')\n",
    "    axarr[idx].scatter(X_train[y_train==1, 0],X_train[y_train==1, 1],c='red', marker='o')\n",
    "    axarr[idx].set_title(tt)\n",
    "axarr[0].set_ylabel('Alcohol', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.2,s='OD280/OD315 of diluted wines',ha='center',va='center',fontsize=12,transform=axarr[1].transAxes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的决策边界图可以看到：Adaboost模型的决策边界比单层决策树的决策边界要复杂的多。也就是说，Adaboost试图用增加模型复杂度而降低偏差的方式去减少总误差，但是过程中引入了方差，可能出现国拟合，因此在训练集和测试集之间的性能存在较大的差距，这就简单地回答的刚刚问题。值的注意的是：与单个分类器相比，Adaboost等Boosting模型增加了计算的复杂度，在实践中需要仔细思考是否愿意为预测性能的相对改善而增加计算成本，而且Boosting方式无法做到现在流行的并行计算的方式进行训练，因为每一步迭代都要基于上一部的基本分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn 同样提供两个接口：AdaBoostClassifier 与AdaBoostRegressor\n",
    "* base_estimator： 可选参数，默认为DecisionTreeClassifier。理论上可以选择任何一个分类或者回归学习器，不过需要支持样本权重。我们常用的一般是CART决策树或者神经网络MLP。\n",
    "* algorithm： 可选参数，默认为SAMME.R。scikit-learn实现了两种Adaboost分类算法，SAMME和SAMME.R。两者的主要区别是弱学习器权重的度量，SAMME使用对样本集分类效果作为弱学习器权重，而SAMME.R使用了对样本集分类的预测概率大小来作为弱学习器权重。由于SAMME.R使用了概率度量的连续值，迭代一般比SAMME快，因此AdaBoostClassifier的默认算法algorithm的值也是SAMME.R。我们一般使用默认的SAMME.R就够了，但是要注意的是使用了SAMME.R， 则弱分类学习器参数base_estimator必须限制使用支持概率预测的分类器。SAMME算法则没有这个限制。\n",
    "* n_estimators： 整数型，可选参数，默认为50。弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是50。\n",
    "* learning_rate： 浮点型，可选参数，默认为1.0。每个弱学习器的权重缩减系数，取值范围为0到1，对于同样的训练集拟合效果，较小的v意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。所以这两个参数n_estimators和learning_rate要一起调参。一般来说，可以从一个小一点的v开始调参，默认是1。\n",
    "* random_state\n",
    "参考https://blog.csdn.net/TeFuirnever/article/details/100276569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
