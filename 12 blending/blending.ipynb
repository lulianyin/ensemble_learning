{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 导言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集成方法思路\n",
    "* 少数服从多少（投票，bagging）\n",
    "* 残差逼近（boosting）\n",
    "* 将前一步作为特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Blending集成学习算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不知道大家小时候有没有过这种经历：老师上课提问到你，那时候你因为开小差而无法立刻得知问题的答案。就在你彷徨的时候，由于你平时人缘比较好，因此周围的同学向你伸出援手告诉了你他们脑中的正确答案，因此你对他们的答案加以总结和分析最终的得出正确答案。相信大家都有过这样的经历，说这个故事的目的是为了引出集成学习家族中的Blending方式，这种集成方式跟我们的故事是十分相像的。如图：(图片来源：https://blog.csdn.net/maqunfi/article/details/82220115)                                                                     \n",
    "\n",
    "![jupyter](./1.png)                                                   \n",
    "下面我们来详细讨论下这个Blending集成学习方式：                             \n",
    "   - (1) 将数据划分为训练集和测试集(test_set)，其中训练集需要再次划分为训练集(train_set)和验证集(val_set)；\n",
    "   - (2) 创建第一层的多个模型，这些模型可以使同质的也可以是异质的；\n",
    "   - (3) 使用train_set训练步骤2中的多个模型，然后用训练好的模型预测val_set和test_set得到val_predict, test_predict1；\n",
    "   - (4) 创建第二层的模型,使用val_predict作为训练集训练第二层的模型；\n",
    "   - (5) 使用第二层训练好的模型对第二层测试集test_predict1进行预测，该结果为整个测试集的结果。                        \n",
    "   \n",
    "![jupyter](./2.png)                               \n",
    "(图片来源：https://blog.csdn.net/sinat_35821976/article/details/83622594)                                                                          \n",
    "\n",
    "在这里，笔者先来梳理下这个过程：                             \n",
    "在(1)步中，总的数据集被分成训练集和测试集，如80%训练集和20%测试集，然后在这80%的训练集中再拆分训练集70%和验证集30%，因此拆分后的数据集由三部分组成：训练集80%* 70%\n",
    "、测试集20%、验证集80%* 30% 。训练集是为了训练模型，测试集是为了调整模型(调参)，测试集则是为了检验模型的优度。                                             \n",
    "在(2)-(3)步中，我们使用训练集创建了K个模型，如SVM、random forests、XGBoost等，这个是第一层的模型。 训练好模型后将**验证集**输入模型进行预测，得到K组不同的输出，我们记作$A_1,...,A_K$，然后将测试集输入K个模型也得到K组输出，我们记作$B_1,...,B_K$，其中$A_i$的样本数与验证集一致，$B_i$的样本数与测试集一致。如果总的样本数有10000个样本，那么使用5600个样本训练了K个模型，输入验证集2400个样本得到K组2400个样本的结果$A_1,...,A_K$，输入测试集2000个得到K组2000个样本的结果$B_1,...,B_K$ 。                             \n",
    "在(4)步中，我们使用K组2400个样本的验证集结果$A_1,...,A_K$作为第二层分类器的特征，验证集的2400个标签为因变量，训练第二层分类器，得到2400个样本的输出。                                  \n",
    "在(5)步中，将输入测试集2000个得到K组2000个样本的结果$B_1,...,B_K$放入第二层分类器，得到2000个测试集的预测结果。                                        \n",
    "\n",
    "![jupyter](./3.jpg)\n",
    "\n",
    "以上是Blending集成方式的过程，接下来我们来分析这个集成方式的优劣：                                          \n",
    "其中一个最重要的优点就是实现简单粗暴，没有太多的理论的分析。但是这个方法的缺点也是显然的：blending只使用了一部分数据集作为留出集进行验证，也就是只能用上数据中的一部分，实际上这对数据来说是很奢侈浪费的。                                                          \n",
    "关于这个缺点，我们以后再做改进，我们先来用一些案例来使用这个集成方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载相关工具包\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training X: (5600, 2)\n",
      "The shape of training y: (5600,)\n",
      "The shape of test X: (2000, 2)\n",
      "The shape of test y: (2000,)\n",
      "The shape of validation X: (2400, 2)\n",
      "The shape of validation y: (2400,)\n"
     ]
    }
   ],
   "source": [
    "# 创建数据\n",
    "from sklearn import datasets \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "data, target = make_blobs(n_samples=10000, centers=2, random_state=1, cluster_std=1.0 )\n",
    "## 创建训练集和测试集\n",
    "X_train1,X_test,y_train1,y_test = train_test_split(data, target, test_size=0.2, random_state=1)\n",
    "## 创建训练集和验证集\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train1, y_train1, test_size=0.3, random_state=1)\n",
    "print(\"The shape of training X:\",X_train.shape)\n",
    "print(\"The shape of training y:\",y_train.shape)\n",
    "print(\"The shape of test X:\",X_test.shape)\n",
    "print(\"The shape of test y:\",y_test.shape)\n",
    "print(\"The shape of validation X:\",X_val.shape)\n",
    "print(\"The shape of validation y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  设置第一层分类器\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clfs = [SVC(probability = True),RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),KNeighborsClassifier()]\n",
    "\n",
    "# 设置第二层分类器\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 输出第一层的验证集结果与测试集结果\n",
    "val_features = np.zeros((X_val.shape[0],len(clfs)))  # 初始化验证集结果\n",
    "test_features = np.zeros((X_test.shape[0],len(clfs)))  # 初始化测试集结果\n",
    "\n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_feature = clf.predict_proba(X_val)[:, 1]\n",
    "    test_feature = clf.predict_proba(X_test)[:,1]\n",
    "    val_features[:,i] = val_feature\n",
    "    test_features[:,i] = test_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将第一层的验证集的结果输入第二层训练第二层分类器\n",
    "lr.fit(val_features,y_val)\n",
    "# 输出预测的结果\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr,test_features,y_test,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在每一折的交叉验证的效果都是非常好的，这个集成学习方法在这个数据集上是十分有效的，不过这个数据集是我们虚拟的，因此大家可以把他用在实际数据上看看效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业：                                  \n",
    "留个小作业吧，我们刚刚的例子是针对人造数据集，表现可能会比较好一点，因为我们使用Blending方式对iris数据集进行预测，并用第四章的决策边界画出来，找找规律。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training X: (84, 4)\n",
      "The shape of training y: (84,)\n",
      "The shape of test X: (30, 4)\n",
      "The shape of test y: (30,)\n",
      "The shape of validation X: (36, 4)\n",
      "The shape of validation y: (36,)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
    "print(\"The shape of training X:\",X_train.shape)\n",
    "print(\"The shape of training y:\",y_train.shape)\n",
    "print(\"The shape of test X:\",X_test.shape)\n",
    "print(\"The shape of test y:\",y_test.shape)\n",
    "print(\"The shape of validation X:\",X_val.shape)\n",
    "print(\"The shape of validation y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.  1.  0.8]\n",
      "[0.93797488 0.94630488 0.99436267 0.80910463 0.98186214]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/wangyanan/opt/miniconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#  设置第一层分类器\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clfs = [SVC(probability = True),RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),KNeighborsClassifier()]\n",
    "\n",
    "# 设置第二层分类器\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# 输出第一层的验证集结果与测试集结果\n",
    "val_features = np.zeros((X_val.shape[0],len(clfs)*3))  # 初始化验证集结果\n",
    "test_features = np.zeros((X_test.shape[0],len(clfs)*3))  # 初始化测试集结果\n",
    "\n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_feature = clf.predict_proba(X_val)\n",
    "    test_feature = clf.predict_proba(X_test)\n",
    "    for ind in [0,1,2]:\n",
    "        val_features[:,3*i+ind] = val_feature[:,ind]\n",
    "        test_features[:,3*i+ind] = test_feature[:,ind]\n",
    "    \n",
    "# 将第一层的验证集的结果输入第二层训练第二层分类器\n",
    "lr.fit(val_features,y_val)\n",
    "# 输出预测的结果\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(clfs[0], X_test,y_test,cv=5))\n",
    "print(cross_val_score(lr,test_features,y_test,cv=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22777426e-02  1.15282883e+00  1.01270418e+00 -1.77316004e-06\n",
      "  1.87051219e+00  1.17294196e+00  2.40894537e+00 -4.01248097e-03\n",
      "  7.06005751e-04  2.02127275e+00  1.04579475e+00 -5.69173401e-03\n",
      "  2.01875234e+00  1.05248569e+00  1.16191027e+00  1.39648643e-02\n",
      "  9.97720461e-01  1.28932533e+00 -7.73198728e-03 -5.33878772e-04\n",
      "  1.14309732e+00  1.41813788e+00  1.36796754e+00 -1.83959362e-03\n",
      "  1.97411495e+00  1.00921655e+00  6.96065608e-03 -1.63808307e-03\n",
      "  1.13558465e+00  2.12527151e+00]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 30 into shape (30,30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-90f69be606ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 30 into shape (30,30)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出单层决策树与Adaboost的决策边界：\n",
    "x_min = test_features[:, 0].min() - 1\n",
    "x_max = test_features[:, 0].max() + 1\n",
    "y_min = test_features[:, 1].min() - 1\n",
    "y_max = test_features[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1))\n",
    "f, axarr = plt.subplots(nrows=1, ncols=3,sharex='col',sharey='row',figsize=(12, 6))\n",
    "Z = lr.predict(test_features)\n",
    "Z = Z.reshape(xx.shape)\n",
    "axarr[0].contourf(xx, yy, Z, alpha=0.3)\n",
    "axarr[0].scatter(X_train[y_train==0, 0],X_train[y_train==0, 1],c='blue', marker='^')\n",
    "axarr[1].scatter(X_train[y_train==1, 0],X_train[y_train==1, 1],c='red', marker='o')\n",
    "axarr[2].scatter(X_train[y_train==2, 0],X_train[y_train==1, 1],c='green', marker='-')\n",
    "\n",
    "axarr[idx].set_title(tt)\n",
    "axarr[0].set_ylabel('Alcohol', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.text(0, -0.2,s='OD280/OD315 of diluted wines',ha='center',va='center',fontsize=12,transform=axarr[1].transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
